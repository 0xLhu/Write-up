# Write-Up: Training Data Poisoning

## Challenge 1: Poison [1/2] (not me)



These two challenges aim to introduce the technique of *federated learning* and the potential dangers associated with it.

*This series of challenges comes with utility functions from the `fl` module. Everything is in the `.zip` provided in the prompt.*

Note: Not all data was accessible as it was hosted on the CTF server; I could only modify my data locally. The notes below were also available for the challenges.



## Federated Learning

Sometimes, instead of performing all training from a single database, it is preferred to train **multiple versions of the model** on varied and potentially decentralized data. For example, recommendation algorithms might train directly on users' machines, then **aggregate the results on a central server**.



### Application Example

The central server creates a base model, saves its weights, and sends them to all clients (base weights are available here: `weights/base_fl.weights.h5`). In our case, there are five clients, and you are one of them. Each client trains the model on its own data (represented in our simulation by `x_clients, y_clients`), then sends their results, the weights, to the server. The server then aggregates the weights by averaging them from all clients, producing a new version of the shared model, which it redistributes, and so on.


Assume the base model has the weights:
$$
M_1 = \{W_1, b_1, W_2, b_2, W_3, b_3, W_4, b_4\}
$$
*(Here, I've used the commonly used notations, $W$ for *weights* and $b$ for *biases*. Everything is considered a "weight" in coding.)*

Then, each client trains the model on their own dataset, which will update the local weights:
$$
i \in \llbracket1, \text{nb_client}\rrbracket, \quad M_1^{(i)} = \{W_1 + \delta W_1^{(i)}, b_1 + \delta b_1^{(i)}, W_2 + \delta W_2^{(i)}, b_2 + \delta b_2^{(i)}, W_3 + \delta W_3^{(i)}, b_3 + \delta b_3^{(i)}, W_4 + \delta W_4^{(i)}, b_4 + \delta b_4^{(i)}\} = \{W_1^{(i)}, b_1^{(i)}, W_2^{(i)}, b_2^{(i)}, W_3^{(i)}, b_3^{(i)}, W_4^{(i)}, b_4^{(i)}\}
$$

Clients send their weights to the server, which aggregates them to create a new version of the shared model:
$$
M_2 = \left\{\sum_{i=1} ^{\text{nb_clients}} W_1^{(i)}, \sum_{i=1} ^{\text{nb_clients}} b_1^{(i)}, \sum_{i=1} ^{\text{nb_clients}} W_2^{(i)}, \sum_{i=1} ^{\text{nb_clients}} b_2^{(i)}, \sum_{i=1} ^{\text{nb_clients}} W_3^{(i)}, \sum_{i=1} ^{\text{nb_clients}} b_3^{(i)}, \sum_{i=1}^{\text{nb_clients}} W_4^{(i)}, \sum_{i=1} ^{\text{nb_clients}} b_4^{(i)} \right\}
$$


And so on.

To visualize this and potentially test it, you have been provided with the **server-side function** that handles weight aggregation. 
It’s called `federated` and simulates the process. It trains the five clients individually and then aggregates their weights. 

On your side, you do not need to simulate the other 4 clients; you only need to focus on your version of the shared model.

First, you need to retrieve the weights and follow the structure of the shared model:

$$
(W_1, b_1, W_2, b_2, W_3, b_3)
$$
*(This is where we start :D)*



Now, the goal is to decrease the model's accuracy. For example, here is the challenge:
*After the POST request, it is indicated: {'message' : Failure, accuracy rate is 0.935, you need to reduce the accuracy to 0.5 to get the flag}*

Useful Links:

- [How ML Model Data Poisoning Works in 5 Minutes](https://medium.com/@sreedeep200/how-ml-model-data-poisoning-works-in-5-minutes-c51000e9cecf)
- [Training Data Poisoning: Examples and Techniques](https://www.lakera.ai/blog/training-data-poisoning#examples-of-real-world-data-poisoning-attacks)
- [How Hackers Can Ruin Your AI Models: Data Poisoning](https://www.linkedin.com/pulse/how-hackers-can-ruin-your-ai-models-data-poisoning-coby-mendoza-fjbhf/)
- [Weights and Biases Overview](https://h2o.ai/wiki/weights-and-biases/)
- [Adversarial Machine Learning](https://medium.com/cltc-bulletin/adversarial-machine-learning-43b6de6aafdb)

I tried modifying the provided code, changing data in "federated_learning", and experimenting with sending data in requests, but nothing worked.

I then continued my research and realized that I needed to modify the weights that correspond to our training data and send them back to the server (the ROOT server, I would say) because we are in federated learning (each server learns locally and sends updates to the root server).

Essentially, imagine you have a system that classifies emails as spam or not. To train this system, you use a large set of emails labeled as spam or not. An attacker can attempt to compromise the system by adding misclassified spam emails to the training set. When the system is trained with this corrupted data, it will likely misclassify some legitimate emails as spam.

Given this understanding, we need to determine what can be added. We cannot modify the already provided code directly; we have a fixed number of weights, and that's it. What we can do is modify these weights, or rather their "matrix," as I understood.



### What is a Weight Matrix?

A weight matrix is a fundamental element in neural network models used to represent model parameters. It is essentially a data structure that stores coefficients that weight the inputs of neurons in each layer of the network.



## Understanding Bias

We have omitted an element: the BIAS.

The term "bias" in the prediction formula represents the bias of the model. The bias is a constant term added to the output of the dot product between the inputs and the weights in a neuron.

In the context of our example of predicting the price of a house, the bias allows the model to make predictions even when all the inputs are zero. For instance, if the bias is a constant term of 50,000, even if the size of the house is zero, the model will still predict a price of 50,000 units due to this bias.

Thus, the bias allows the model to better fit the training data by learning an offset from the origin, which can be crucial for the model's performance in certain cases.



## Solutions

If you’ve read this far, thank you, and let’s move on to practice. By doing some research online, you can find plenty of information on how to approach this.

### Step 1: Review the Code

Identify where modifications need to be made, specifically before the request to the server. You will intervene before the local training of weights, adding noise (which was the simplest method for me; other methods likely exist).

### Step 2: Adding Noise

There are several types of noise; a great article explains this: [Guide to Adding Noise to Your Data Using Python and NumPy](https://medium.com/@ms_somanna/guide-to-adding-noise-to-your-data-using-python-and-numpy-c8be815df524)

The goal here is to manipulate `local_result`, which represents our data locally.




